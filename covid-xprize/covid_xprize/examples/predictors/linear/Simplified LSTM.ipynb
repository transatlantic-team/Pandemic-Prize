{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T09:27:00.425127Z",
     "start_time": "2020-12-15T09:27:00.339307Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T09:27:01.198133Z",
     "start_time": "2020-12-15T09:27:00.608729Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi']= 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T11:33:33.326870Z",
     "start_time": "2020-12-15T11:33:33.246743Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "\n",
    "# Data\n",
    "from transat.data import HYPOTHETICAL_SUBMISSION_DATE\n",
    "from transat.data.load import download_historical, load_historical\n",
    "from transat.data.split import split_historical\n",
    "from transat.data.transform import preprocess_historical_basic, dataframe_to_array\n",
    "\n",
    "# Metric\n",
    "from transat.metric import mae\n",
    "\n",
    "# Scenario/Simulation\n",
    "from transat.data.scenario import generate_scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T11:33:35.500547Z",
     "start_time": "2020-12-15T11:33:33.870378Z"
    }
   },
   "outputs": [],
   "source": [
    "download_historical()\n",
    "df = load_historical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T11:33:36.024459Z",
     "start_time": "2020-12-15T11:33:35.502737Z"
    }
   },
   "outputs": [],
   "source": [
    "df = preprocess_historical_basic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T11:33:36.092672Z",
     "start_time": "2020-12-15T11:33:36.027040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting at :  2020-07-31\n"
     ]
    }
   ],
   "source": [
    "print(\"Spliting at : \", HYPOTHETICAL_SUBMISSION_DATE)\n",
    "df_train, df_test = split_historical(df, HYPOTHETICAL_SUBMISSION_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T11:33:38.892297Z",
     "start_time": "2020-12-15T11:33:36.094581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (48412, 30, 13)\n",
      "y_train shape:  (48412, 1, 1)\n",
      "\n",
      "X_test  shape:  (27930, 30, 13)\n",
      "y_test  shape:  (27930, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "nb_lookback_days = 30\n",
    "sequence_format = True\n",
    "neg_npis = False\n",
    "\n",
    "(X_train, y_train), (X_cols, y_col) = dataframe_to_array(df_train, nb_lookback_days=nb_lookback_days,\n",
    "    sequence_format=sequence_format, neg_npis=neg_npis)\n",
    "(X_test, y_test), _ = dataframe_to_array(df_test, nb_lookback_days=nb_lookback_days,\n",
    "    sequence_format=sequence_format, neg_npis=neg_npis)\n",
    "\n",
    "# X_train, y_train = X_train.reshape(X_train.shape[0], -1), y_train.reshape(-1)\n",
    "# X_test, y_test = X_test.reshape(X_test.shape[0], -1), y_test.reshape(-1)\n",
    "\n",
    "print(\"X_train shape: \", np.shape(X_train))\n",
    "print(\"y_train shape: \", np.shape(y_train))\n",
    "print()\n",
    "print(\"X_test  shape: \", np.shape(X_test))\n",
    "print(\"y_test  shape: \", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T11:33:45.088928Z",
     "start_time": "2020-12-15T11:33:44.948213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and train Lasso model.\n",
    "# Set positive=True to enforce assumption that cases are positively correlated\n",
    "# with future cases and npis are negatively correlated.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.utils import shuffle\n",
    "# X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_valid , y_train, y_valid= train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=301\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T11:54:15.049461Z",
     "start_time": "2020-12-15T11:52:12.204408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1211/1211 [==============================] - 23s 19ms/step - loss: 5.2263e-04\n",
      "Epoch 2/5\n",
      "1211/1211 [==============================] - 23s 19ms/step - loss: 1.4386e-04\n",
      "Epoch 3/5\n",
      "1211/1211 [==============================] - 25s 20ms/step - loss: 1.3216e-04\n",
      "Epoch 4/5\n",
      "1211/1211 [==============================] - 24s 20ms/step - loss: 1.1229e-04\n",
      "Epoch 5/5\n",
      "1211/1211 [==============================] - 24s 20ms/step - loss: 1.1879e-04\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LSTM:\n",
    "    \n",
    "    def fit(self, X, y, epochs=1, batch_size=32):\n",
    "        \n",
    "        # Build Model\n",
    "        if not(hasattr(self, \"model\")):\n",
    "            input_shape = X.shape[1:]\n",
    "            self.model = self.build_model(input_shape)\n",
    "            \n",
    "        # Pre-process data\n",
    "        self.fit_preprocess(X, y)\n",
    "        X, y = self.transform(X, y)\n",
    "        \n",
    "        # Fit Model\n",
    "        self.model.fit(X, y, epochs=epochs, batch_size=batch_size)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = self.transform(X)\n",
    "        \n",
    "        y = self.model.predict(X).reshape(-1)\n",
    "        \n",
    "        # Inverse preprocessing\n",
    "#         y = y * self.std[0] + self.mean[0]\n",
    "        y = y * (self.max[0] - self.min[0]) + self.min[0]\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def fit_preprocess(self, X, y):\n",
    "        # MinMax (x - min) / (max - min)\n",
    "        self.min = X.reshape(-1, X.shape[-1]).min(axis=0)\n",
    "        self.max = X.reshape(-1, X.shape[-1]).max(axis=0)\n",
    "\n",
    "        # Normalization\n",
    "#         self.mean = X.reshape(-1, X.shape[-1]).mean(axis=0)\n",
    "#         self.std = X.reshape(-1, X.shape[-1]).std(axis=0)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = (X - self.min) / (self.max - self.min)\n",
    "#         X = (X - self.mean) / self.std\n",
    "        if y is not None:\n",
    "            y = (y - self.min[0]) / (self.max[0] - self.min[0])\n",
    "#             y = (y - self.mean[0]) / self.std[0]\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def build_model(self, input_shape):\n",
    "\n",
    "        input = tf.keras.Input(shape=input_shape, name='input')\n",
    "        x = tf.keras.layers.LSTM(32, return_sequences=True)(input)\n",
    "        x = tf.keras.layers.LSTM(32)(x)\n",
    "#         x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        output = tf.keras.layers.Dense(1, activation=None, name='output')(x)\n",
    "        model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "\n",
    "        model.compile(\n",
    "            loss=tf.losses.MeanSquaredError(),\n",
    "            optimizer=tf.optimizers.Adam(),\n",
    "            # metrics=[tf.metrics.MeanAbsoluteError()]\n",
    "        )\n",
    "\n",
    "        return model\n",
    "    \n",
    "model = LSTM()\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T12:39:13.385085Z",
     "start_time": "2020-12-15T12:35:15.836155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1211/1211 [==============================] - 23s 19ms/step - loss: 7.4191e-05\n",
      "Epoch 2/10\n",
      "1211/1211 [==============================] - 23s 19ms/step - loss: 7.2329e-05\n",
      "Epoch 3/10\n",
      "1211/1211 [==============================] - 24s 20ms/step - loss: 6.6996e-05\n",
      "Epoch 4/10\n",
      "1211/1211 [==============================] - 26s 21ms/step - loss: 7.3871e-05\n",
      "Epoch 5/10\n",
      "1211/1211 [==============================] - 25s 21ms/step - loss: 6.5412e-05\n",
      "Epoch 6/10\n",
      "1211/1211 [==============================] - 24s 20ms/step - loss: 6.2030e-05\n",
      "Epoch 7/10\n",
      "1211/1211 [==============================] - 23s 19ms/step - loss: 6.2617e-05\n",
      "Epoch 8/10\n",
      "1211/1211 [==============================] - 22s 19ms/step - loss: 5.7826e-05\n",
      "Epoch 9/10\n",
      "1211/1211 [==============================] - 24s 19ms/step - loss: 6.2043e-05\n",
      "Epoch 10/10\n",
      "1211/1211 [==============================] - 23s 19ms/step - loss: 5.6388e-05\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T12:41:08.596836Z",
     "start_time": "2020-12-15T12:39:46.884080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 932.2693972831084\n",
      "Valid MAE: 901.8480131745767\n",
      "Test MAE: 3669.418458792935\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "train_preds = model.predict(X_train)\n",
    "train_preds = np.maximum(train_preds, 0) # Don't predict negative cases\n",
    "print('Train MAE:', mae(train_preds, y_train))\n",
    "\n",
    "valid_preds = model.predict(X_valid)\n",
    "valid_preds = np.maximum(valid_preds, 0) # Don't predict negative cases\n",
    "print('Valid MAE:', mae(valid_preds, y_valid))\n",
    "\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds = np.maximum(test_preds, 0) # Don't predict negative cases\n",
    "print('Test MAE:', mae(test_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T10:15:32.556132Z",
     "start_time": "2020-12-15T10:15:32.427940Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_scenario(model, X_scenario, y_scenario, seq=False):\n",
    "    # Simulate scenario\n",
    "\n",
    "    X_sim = X_scenario.copy()\n",
    "    X_sim_cases = X_sim[:,:,:1]\n",
    "    X_sim_npis = X_sim[:,:,1:]\n",
    "    y_sim = np.zeros(np.shape(y_scenario))\n",
    "\n",
    "    nb_lookback_days = X_sim.shape[1]\n",
    "\n",
    "    for d in range(y_sim.shape[1]):\n",
    "        \n",
    "        if seq:\n",
    "            y = model.predict(X_sim)\n",
    "        else:\n",
    "            y = model.predict(X_sim.reshape(1,-1))\n",
    "        y_sim[0,d,0] = max(y[0], 0)\n",
    "\n",
    "        # Assuming constant NPIs here\n",
    "        X_sim_npis = np.concatenate([X_sim_npis[:,1:], X_sim_npis[:,-1:]], axis=1)\n",
    "        X_sim_cases = np.concatenate([X_sim_cases[:,1:], y.reshape(-1, 1, 1)], axis=1)\n",
    "\n",
    "        X_sim =  np.concatenate([X_sim_cases, X_sim_npis], axis=-1)\n",
    "        X_sim = np.array(X_sim)\n",
    "    \n",
    "    return y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T10:15:33.595552Z",
     "start_time": "2020-12-15T10:15:33.541287Z"
    }
   },
   "outputs": [],
   "source": [
    "def viz_scenario(geo_id, X_scenario, y_scenario, y_sim):\n",
    "    mae_error = mae(y_scenario, y_sim)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(geo_id)\n",
    "\n",
    "    plot_input_x = np.arange(X_scenario.shape[1])\n",
    "    plot_input_y = X_scenario[:,:,:1].reshape(-1)\n",
    "\n",
    "    plt.plot(plot_input_x, plot_input_y, label=\"Input Scenario\")\n",
    "\n",
    "    plot_output_x = np.arange(y_scenario.shape[1])+X_scenario.shape[1]\n",
    "    plot_output_x = np.concatenate([plot_input_x[-1:], plot_output_x])\n",
    "    plot_output_y = np.concatenate([plot_input_y[-1:], y_scenario.reshape(-1)])\n",
    "    plt.plot(plot_output_x, plot_output_y, label=\"Output Scenario\")\n",
    "\n",
    "\n",
    "    plot_output_y = np.concatenate([plot_input_y[-1:], y_sim.reshape(-1)])\n",
    "    plt.plot(plot_output_x, plot_output_y, label=\"Output Simulation\")\n",
    "\n",
    "    plt.ylabel(\"New Cases\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    ax = plt.gca()\n",
    "    plt.text(0.3, 0.5, f\"$MAE={mae_error:.2f}$\", transform=ax.transAxes)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T12:06:06.995597Z",
     "start_time": "2020-12-15T12:06:05.441497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c3d2a67fa74b4cbf68c31ee2015032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='GeoID:', index=87, options=('Afghanistan__nan', 'Albania__nan', 'Aâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_scenario(geo_id, model, seq=True)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interactive_scenario(geo_id, model, seq=True):\n",
    "    nb_future_days=30\n",
    "\n",
    "    X_scenario , y_scenario = generate_scenario(df_train, df_test, geo_id, nb_lookback_days=nb_lookback_days,\n",
    "        nb_future_days=nb_future_days, sequence_format=sequence_format)\n",
    "\n",
    "    y_sim = simulate_scenario(model, X_scenario, y_scenario, seq=seq)\n",
    "\n",
    "    viz_scenario(geo_id, X_scenario, y_scenario, y_sim)\n",
    "    \n",
    "geo_ids = sorted(df.GeoID.unique())\n",
    "\n",
    "w_geo_id = widgets.Dropdown(\n",
    "    options=geo_ids,\n",
    "    value='France__nan',\n",
    "    description='GeoID:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "interact(interactive_scenario, geo_id=w_geo_id, model=fixed(model), seq=fixed(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
