{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:23:47.095038Z",
     "start_time": "2020-12-15T15:23:47.067516Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:23:48.844132Z",
     "start_time": "2020-12-15T15:23:47.098612Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi']= 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:23:49.992615Z",
     "start_time": "2020-12-15T15:23:48.846536Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "\n",
    "# Data\n",
    "from transat.data import HYPOTHETICAL_SUBMISSION_DATE\n",
    "from transat.data.load import download_historical, load_historical\n",
    "from transat.data.split import split_historical\n",
    "from transat.data.transform import preprocess_historical_basic, dataframe_to_array, NPI_COLS, CASES_COL\n",
    "\n",
    "# Metric\n",
    "from transat.metric import mae\n",
    "\n",
    "# Scenario/Simulation\n",
    "from transat.data.scenario import generate_scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:24:00.000047Z",
     "start_time": "2020-12-15T15:23:49.994993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T15:24:01.407294Z",
     "start_time": "2020-12-15T15:24:00.010525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Our World In Data Coronavirus data to \n",
      "\tdata/owid_2020-12-15.csv\n"
     ]
    }
   ],
   "source": [
    "def download_csv(url, path, prefix):\n",
    "    \"\"\"\n",
    "    Downloads a CSV from 'url', saves it to 'path' folder with filename 'prefix'_DD-MM-YYYY formatted at today's date\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import os\n",
    "    import datetime\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    today = str(datetime.date.today())\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    filepath = f'{path}/{prefix}_{today}.csv'\n",
    "    open(filepath, 'wb').write(response.content)\n",
    "    return filepath\n",
    "\n",
    "def update_owid(path):\n",
    "    \"\"\"\n",
    "    Updates Our World In Data database and saves it to 'path' folder. Renames it to owid_DD-MM-YYYY with today's date\n",
    "    \"\"\"\n",
    "    filepath = download_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv', path, 'owid')\n",
    "    print(f'Downloaded Our World In Data Coronavirus data to \\n\\t{filepath}')\n",
    "    return filepath\n",
    "\n",
    "# Create a \"owid-data\"\n",
    "owid_filepath = update_owid(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:04:42.727637Z",
     "start_time": "2020-12-15T16:04:42.323555Z"
    }
   },
   "outputs": [],
   "source": [
    "df_owid = pd.read_csv(owid_filepath)\n",
    "\n",
    "countryCode_2_population = {iso:pop for iso,pop in zip(df_owid.iso_code, df_owid.population)}\n",
    "\n",
    "# df_owid = pd.DataFrame({\n",
    "#     \"CountryCode\": df_owid.iso_code.tolist(),\n",
    "#     \"Population\": df_owid.population.tolist()\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:23:44.786876Z",
     "start_time": "2020-12-15T16:23:43.177702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92834, 49)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_historical()\n",
    "df = load_historical()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:23:46.824999Z",
     "start_time": "2020-12-15T16:23:45.661678Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Population\"] = 1\n",
    "for ccode, pop in countryCode_2_population.items():\n",
    "    df.loc[df.CountryCode == ccode, \"Population\"] = pop\n",
    "df = df[df.Population > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:23:47.597552Z",
     "start_time": "2020-12-15T16:23:47.552207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88995, 50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:25:18.249776Z",
     "start_time": "2020-12-15T16:25:18.205700Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_historical_with_population(df, cases_col=CASES_COL, npi_cols=NPI_COLS):\n",
    "    \"\"\"Create a copy of preprocessed data.\"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Add RegionID column that combines CountryName and RegionName for easier manipulation of data\n",
    "    df[\"GeoID\"] = df[\"CountryName\"] + \"__\" + df[\"RegionName\"].astype(str)\n",
    "\n",
    "    # Add new cases column\n",
    "    df[\"NewCases\"] = df.groupby(\"GeoID\").ConfirmedCases.diff().fillna(0)\n",
    "    \n",
    "    df[\"NewCases\"] = df.NewCases / df.Population\n",
    "\n",
    "    # Keep only columns of interest\n",
    "    id_cols = [\"CountryName\", \"RegionName\", \"GeoID\", \"Date\"]\n",
    "\n",
    "    df = df[id_cols + cases_col + npi_cols]\n",
    "\n",
    "    # Fill any missing case values by interpolation and setting NaNs to 0\n",
    "    df.update(\n",
    "        df.groupby(\"GeoID\").NewCases.apply(lambda group: group.interpolate()).fillna(0)\n",
    "    )\n",
    "\n",
    "    # Fill any missing NPIs by assuming they are the same as previous day\n",
    "    for npi_col in npi_cols:\n",
    "        df.update(df.groupby(\"GeoID\")[npi_col].ffill().fillna(0))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:25:33.305403Z",
     "start_time": "2020-12-15T16:25:32.859332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88995, 17)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess_historical_with_population(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:37:44.838349Z",
     "start_time": "2020-12-15T16:37:44.552565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b4ffd2da7f4ad2937b0485e38955c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='GeoID:', index=84, options=('Afghanistan__nan', 'Albania__nan', 'Aâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_new_cases(geo_id, df)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_new_cases(geo_id, df):\n",
    "    \n",
    "    nc = df.loc[df.GeoID == geo_id, \"NewCases\"].tolist()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(nc)\n",
    "    plt.ylim(-0.0001,0.002)\n",
    "    plt.show()\n",
    "    \n",
    "geo_ids = sorted(df.GeoID.unique())\n",
    "\n",
    "w_geo_id = widgets.Dropdown(\n",
    "    options=geo_ids,\n",
    "    value='France__nan',\n",
    "    description='GeoID:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "interact(plot_new_cases, geo_id=w_geo_id, df=fixed(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:26:14.883344Z",
     "start_time": "2020-12-15T16:26:14.829291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting at :  2020-07-31\n"
     ]
    }
   ],
   "source": [
    "print(\"Spliting at : \", HYPOTHETICAL_SUBMISSION_DATE)\n",
    "df_train, df_test = split_historical(df, HYPOTHETICAL_SUBMISSION_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:26:21.006416Z",
     "start_time": "2020-12-15T16:26:18.763502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (46410, 30, 13)\n",
      "y_train shape:  (46410, 1, 1)\n",
      "\n",
      "X_test  shape:  (26775, 30, 13)\n",
      "y_test  shape:  (26775, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "nb_lookback_days = 30\n",
    "sequence_format = True\n",
    "neg_npis = False\n",
    "\n",
    "(X_train, y_train), (X_cols, y_col) = dataframe_to_array(df_train, nb_lookback_days=nb_lookback_days,\n",
    "    sequence_format=sequence_format, neg_npis=neg_npis)\n",
    "(X_test, y_test), _ = dataframe_to_array(df_test, nb_lookback_days=nb_lookback_days,\n",
    "    sequence_format=sequence_format, neg_npis=neg_npis)\n",
    "\n",
    "# X_train, y_train = X_train.reshape(X_train.shape[0], -1), y_train.reshape(-1)\n",
    "# X_test, y_test = X_test.reshape(X_test.shape[0], -1), y_test.reshape(-1)\n",
    "\n",
    "print(\"X_train shape: \", np.shape(X_train))\n",
    "print(\"y_train shape: \", np.shape(y_train))\n",
    "print()\n",
    "print(\"X_test  shape: \", np.shape(X_test))\n",
    "print(\"y_test  shape: \", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:26:23.701207Z",
     "start_time": "2020-12-15T16:26:22.199664Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and train Lasso model.\n",
    "# Set positive=True to enforce assumption that cases are positively correlated\n",
    "# with future cases and npis are negatively correlated.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.utils import shuffle\n",
    "# X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_valid , y_train, y_valid= train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=301\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:28:27.611311Z",
     "start_time": "2020-12-15T16:26:23.703233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1161/1161 [==============================] - 22s 19ms/step - loss: 4.5067e-04\n",
      "Epoch 2/5\n",
      "1161/1161 [==============================] - 23s 20ms/step - loss: 2.4966e-04\n",
      "Epoch 3/5\n",
      "1161/1161 [==============================] - 26s 23ms/step - loss: 2.1602e-04\n",
      "Epoch 4/5\n",
      "1161/1161 [==============================] - 25s 21ms/step - loss: 1.7829e-04\n",
      "Epoch 5/5\n",
      "1161/1161 [==============================] - 24s 21ms/step - loss: 1.8632e-04\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LSTM:\n",
    "    \n",
    "    def fit(self, X, y, epochs=1, batch_size=32):\n",
    "        \n",
    "        # Build Model\n",
    "        if not(hasattr(self, \"model\")):\n",
    "            input_shape = X.shape[1:]\n",
    "            self.model = self.build_model(input_shape)\n",
    "            \n",
    "        # Pre-process data\n",
    "        self.fit_preprocess(X, y)\n",
    "        X, y = self.transform(X, y)\n",
    "        \n",
    "        # Fit Model\n",
    "        self.model.fit(X, y, epochs=epochs, batch_size=batch_size)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = self.transform(X)\n",
    "        \n",
    "        y = self.model.predict(X).reshape(-1)\n",
    "        \n",
    "        # Inverse preprocessing\n",
    "#         y = y * self.std[0] + self.mean[0]\n",
    "        y = y * (self.max[0] - self.min[0]) + self.min[0]\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def fit_preprocess(self, X, y):\n",
    "        # MinMax (x - min) / (max - min)\n",
    "        self.min = X.reshape(-1, X.shape[-1]).min(axis=0)\n",
    "        self.max = X.reshape(-1, X.shape[-1]).max(axis=0)\n",
    "\n",
    "        # Normalization\n",
    "#         self.mean = X.reshape(-1, X.shape[-1]).mean(axis=0)\n",
    "#         self.std = X.reshape(-1, X.shape[-1]).std(axis=0)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = (X - self.min) / (self.max - self.min)\n",
    "#         X = (X - self.mean) / self.std\n",
    "        if y is not None:\n",
    "            y = (y - self.min[0]) / (self.max[0] - self.min[0])\n",
    "#             y = (y - self.mean[0]) / self.std[0]\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def build_model(self, input_shape):\n",
    "\n",
    "        input = tf.keras.Input(shape=input_shape, name='input')\n",
    "        x = tf.keras.layers.LSTM(32, return_sequences=True)(input)\n",
    "        x = tf.keras.layers.LSTM(32)(x)\n",
    "#         x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        output = tf.keras.layers.Dense(1, activation=None, name='output')(x)\n",
    "        model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "\n",
    "        model.compile(\n",
    "            loss=tf.losses.MeanSquaredError(),\n",
    "            optimizer=tf.optimizers.Adam(),\n",
    "            # metrics=[tf.metrics.MeanAbsoluteError()]\n",
    "        )\n",
    "\n",
    "        return model\n",
    "    \n",
    "model = LSTM()\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T12:39:13.385085Z",
     "start_time": "2020-12-15T12:35:15.836155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1211/1211 [==============================] - 5s 5ms/step - loss: 7.2632e-05\n",
      "Epoch 2/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 7.0572e-05\n",
      "Epoch 3/30\n",
      "1211/1211 [==============================] - 5s 5ms/step - loss: 7.2640e-05\n",
      "Epoch 4/30\n",
      "1211/1211 [==============================] - 5s 5ms/step - loss: 6.5973e-05\n",
      "Epoch 5/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 6.9094e-05\n",
      "Epoch 6/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 6.5384e-05\n",
      "Epoch 7/30\n",
      "1211/1211 [==============================] - 5s 5ms/step - loss: 6.3773e-05\n",
      "Epoch 8/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.7737e-05\n",
      "Epoch 9/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.5563e-05\n",
      "Epoch 10/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.5472e-05\n",
      "Epoch 11/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.8449e-05\n",
      "Epoch 12/30\n",
      "1211/1211 [==============================] - 5s 5ms/step - loss: 5.9566e-05\n",
      "Epoch 13/30\n",
      "1211/1211 [==============================] - 5s 5ms/step - loss: 5.2747e-05\n",
      "Epoch 14/30\n",
      "1211/1211 [==============================] - 5s 5ms/step - loss: 5.3743e-05\n",
      "Epoch 15/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.4622e-05\n",
      "Epoch 16/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.1865e-05\n",
      "Epoch 17/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.4016e-05\n",
      "Epoch 18/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.1654e-05\n",
      "Epoch 19/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 4.9381e-05\n",
      "Epoch 20/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.3894e-05\n",
      "Epoch 21/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.4136e-05\n",
      "Epoch 22/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.1377e-05\n",
      "Epoch 23/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.0527e-05\n",
      "Epoch 24/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 4.8081e-05\n",
      "Epoch 25/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.1161e-05\n",
      "Epoch 26/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.1452e-05\n",
      "Epoch 27/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 5.4104e-05\n",
      "Epoch 28/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 4.7259e-05\n",
      "Epoch 29/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 4.5457e-05\n",
      "Epoch 30/30\n",
      "1211/1211 [==============================] - 6s 5ms/step - loss: 4.7393e-05\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T12:41:08.596836Z",
     "start_time": "2020-12-15T12:39:46.884080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 939.424174252276\n",
      "Valid MAE: 901.3265630273827\n",
      "Test MAE: 3553.7698564215925\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "train_preds = model.predict(X_train)\n",
    "train_preds = np.maximum(train_preds, 0) # Don't predict negative cases\n",
    "print('Train MAE:', mae(train_preds, y_train))\n",
    "\n",
    "valid_preds = model.predict(X_valid)\n",
    "valid_preds = np.maximum(valid_preds, 0) # Don't predict negative cases\n",
    "print('Valid MAE:', mae(valid_preds, y_valid))\n",
    "\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds = np.maximum(test_preds, 0) # Don't predict negative cases\n",
    "print('Test MAE:', mae(test_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:29:46.001538Z",
     "start_time": "2020-12-15T16:29:45.953444Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_scenario(model, X_scenario, y_scenario, seq=False):\n",
    "    # Simulate scenario\n",
    "\n",
    "    X_sim = X_scenario.copy()\n",
    "    X_sim_cases = X_sim[:,:,:1]\n",
    "    X_sim_npis = X_sim[:,:,1:]\n",
    "    y_sim = np.zeros(np.shape(y_scenario))\n",
    "\n",
    "    nb_lookback_days = X_sim.shape[1]\n",
    "\n",
    "    for d in range(y_sim.shape[1]):\n",
    "        \n",
    "        if seq:\n",
    "            y = model.predict(X_sim)\n",
    "        else:\n",
    "            y = model.predict(X_sim.reshape(1,-1))\n",
    "        y_sim[0,d,0] = max(y[0], 0)\n",
    "\n",
    "        # Assuming constant NPIs here\n",
    "        X_sim_npis = np.concatenate([X_sim_npis[:,1:], X_sim_npis[:,-1:]], axis=1)\n",
    "        X_sim_cases = np.concatenate([X_sim_cases[:,1:], y.reshape(-1, 1, 1)], axis=1)\n",
    "\n",
    "        X_sim =  np.concatenate([X_sim_cases, X_sim_npis], axis=-1)\n",
    "        X_sim = np.array(X_sim)\n",
    "    \n",
    "    return y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:29:46.551531Z",
     "start_time": "2020-12-15T16:29:46.504884Z"
    }
   },
   "outputs": [],
   "source": [
    "def viz_scenario(geo_id, X_scenario, y_scenario, y_sim):\n",
    "    mae_error = mae(y_scenario, y_sim)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(geo_id)\n",
    "\n",
    "    plot_input_x = np.arange(X_scenario.shape[1])\n",
    "    plot_input_y = X_scenario[:,:,:1].reshape(-1)\n",
    "\n",
    "    plt.plot(plot_input_x, plot_input_y, label=\"Input Scenario\")\n",
    "\n",
    "    plot_output_x = np.arange(y_scenario.shape[1])+X_scenario.shape[1]\n",
    "    plot_output_x = np.concatenate([plot_input_x[-1:], plot_output_x])\n",
    "    plot_output_y = np.concatenate([plot_input_y[-1:], y_scenario.reshape(-1)])\n",
    "    plt.plot(plot_output_x, plot_output_y, label=\"Output Scenario\")\n",
    "\n",
    "\n",
    "    plot_output_y = np.concatenate([plot_input_y[-1:], y_sim.reshape(-1)])\n",
    "    plt.plot(plot_output_x, plot_output_y, label=\"Output Simulation\")\n",
    "\n",
    "    plt.ylabel(\"New Cases\")\n",
    "    plt.xlabel(\"Days\")\n",
    "    ax = plt.gca()\n",
    "    plt.text(0.3, 0.5, f\"$MAE={mae_error:.2f}$\", transform=ax.transAxes)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:29:48.795782Z",
     "start_time": "2020-12-15T16:29:47.144085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0614388ecc5341709766aec75fc56a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='GeoID:', index=84, options=('Afghanistan__nan', 'Albania__nan', 'Aâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_scenario(geo_id, model, seq=True)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interactive_scenario(geo_id, model, seq=True):\n",
    "    nb_future_days=30\n",
    "\n",
    "    X_scenario , y_scenario = generate_scenario(df_train, df_test, geo_id, nb_lookback_days=nb_lookback_days,\n",
    "        nb_future_days=nb_future_days, sequence_format=sequence_format)\n",
    "\n",
    "    y_sim = simulate_scenario(model, X_scenario, y_scenario, seq=seq)\n",
    "\n",
    "    viz_scenario(geo_id, X_scenario, y_scenario, y_sim)\n",
    "    \n",
    "geo_ids = sorted(df.GeoID.unique())\n",
    "\n",
    "w_geo_id = widgets.Dropdown(\n",
    "    options=geo_ids,\n",
    "    value='France__nan',\n",
    "    description='GeoID:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "interact(interactive_scenario, geo_id=w_geo_id, model=fixed(model), seq=fixed(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:30:19.040033Z",
     "start_time": "2020-12-15T16:30:18.995562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65273512.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countryCode_2_population[\"FRA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
